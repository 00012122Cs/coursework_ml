{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 02 - Data Preprocessing\nThis notebook focuses on preparing the life expectancy dataset for modelling by handling quality issues, engineering informative features, and exporting train/test splits."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Pipeline Overview\n1. Load and standardise the raw WHO export.\n2. Remove duplicates and impossible values.\n3. Impute missing data using KNN for numeric columns and the mode for categoricals.\n4. Engineer temporal and regional features.\n5. Apply OneHotEncoder + scaling inside a `ColumnTransformer`.\n6. Perform an 80/20 train-test split and export processed artefacts to `data/processed/`."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import json\nimport re\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple\n\nimport joblib\nimport numpy as np\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import KNNImputer, SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\nDATA_PATH = Path('../data/life_expectancy.csv')\nPROCESSED_DIR = Path('../data/processed')\nPROCESSED_DIR.mkdir(parents=True, exist_ok=True)\nMODELS_DIR = Path('../models')\nMODELS_DIR.mkdir(parents=True, exist_ok=True)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def load_life_expectancy_data(data_path: Path = DATA_PATH) -> pd.DataFrame:\n    text = data_path.read_text(encoding='utf-8').strip()\n    if text.startswith('{'):\n        payload = json.loads(text)\n        records = payload.get('value', [])\n        df = pd.DataFrame(records)\n    else:\n        df = pd.read_csv(data_path)\n    return df\n\n\ndef to_snake_case(value: str) -> str:\n    value = value or ''\n    value = re.sub(r'[^0-9a-zA-Z]+', '_', value)\n    return value.strip('_').lower()\n\n\ndef clean_column_names(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n    df.columns = [to_snake_case(col) for col in df.columns]\n    return df\n\n\ndef map_gender(value: str) -> str:\n    mapping = {\n        'sex_mle': 'Male',\n        'sex_fmle': 'Female',\n        'sex_btsx': 'Both sexes'\n    }\n    if not isinstance(value, str):\n        return 'Both sexes'\n    return mapping.get(value.lower(), value)\n\n\ndef enrich_columns(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n    df['gender'] = df.get('dim1', 'SEX_BTSX').apply(map_gender)\n    df['country_code'] = df.get('spatial_dim')\n    df['continent_code'] = df.get('parent_location_code')\n    df['continent'] = df.get('parent_location')\n    df['year'] = df.get('time_dim').astype(int)\n    df['life_expectancy'] = df.get('numeric_value')\n    df['life_expectancy_low'] = df.get('low')\n    df['life_expectancy_high'] = df.get('high')\n    df['record_date'] = pd.to_datetime(df.get('date'), errors='coerce')\n    df['period_start'] = pd.to_datetime(df.get('time_dimension_begin'), errors='coerce')\n    df['period_end'] = pd.to_datetime(df.get('time_dimension_end'), errors='coerce')\n    df['value_range'] = df['life_expectancy_high'] - df['life_expectancy_low']\n    drop_cols = [\n        '@odata_context', 'dim1', 'dim1_type', 'dim2', 'dim2_type', 'dim3', 'dim3_type',\n        'time_dimension_value', 'value'\n    ]\n    df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)\n    return df"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "raw_df = load_life_expectancy_data()\ndf = enrich_columns(clean_column_names(raw_df))\nprint(f'Initial shape: {df.shape}')\n\nvalid_mask = df['life_expectancy'].between(0, 120)\ndf = df[valid_mask]\ndf = df.drop_duplicates(subset=['country_code', 'year', 'gender'])\nprint(f'Shape after quality filters: {df.shape}')"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "df['continent_encoded'] = df['continent'].astype('category').cat.codes\nyear_min = df['year'].min()\nyear_max = df['year'].max()\ndf['year_normalized'] = (df['year'] - year_min) / (year_max - year_min)\ndf['continent_life_expectancy_mean'] = df.groupby('continent')['life_expectancy'].transform('mean')\ndf['country_life_expectancy_mean'] = df.groupby('country_code')['life_expectancy'].transform('mean')\n\ndf.head()"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "feature_cols = [\n    'year', 'gender', 'continent', 'country_code', 'life_expectancy_low', 'life_expectancy_high',\n    'value_range', 'year_normalized', 'continent_life_expectancy_mean', 'country_life_expectancy_mean',\n    'continent_encoded'\n]\ntarget_col = 'life_expectancy'\n\nX = df[feature_cols].copy()\ny = df[target_col].copy()\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, shuffle=True\n)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "numeric_features = [\n    'year', 'life_expectancy_low', 'life_expectancy_high', 'value_range', 'year_normalized',\n    'continent_life_expectancy_mean', 'country_life_expectancy_mean', 'continent_encoded'\n]\ncategorical_features = ['gender', 'continent', 'country_code']\n\nnumeric_transformer = Pipeline(\n    steps=[\n        ('imputer', KNNImputer(n_neighbors=5)),\n        ('scaler', StandardScaler())\n    ]\n)\n\ncategorical_transformer = Pipeline(\n    steps=[\n        ('imputer', SimpleImputer(strategy='most_frequent')),\n        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n    ]\n)\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('numeric', numeric_transformer, numeric_features),\n        ('categorical', categorical_transformer, categorical_features)\n    ]\n)\n\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_test_processed = preprocessor.transform(X_test)\n\nfeature_names = preprocessor.get_feature_names_out()\nX_train_processed_df = pd.DataFrame(X_train_processed, columns=feature_names)\nX_test_processed_df = pd.DataFrame(X_test_processed, columns=feature_names)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "clean_path = PROCESSED_DIR / 'life_expectancy_clean.csv'\ntrain_path = PROCESSED_DIR / 'X_train_processed.csv'\ntest_path = PROCESSED_DIR / 'X_test_processed.csv'\ny_train_path = PROCESSED_DIR / 'y_train.csv'\ny_test_path = PROCESSED_DIR / 'y_test.csv'\n\ndf.to_csv(clean_path, index=False)\nX_train_processed_df.to_csv(train_path, index=False)\nX_test_processed_df.to_csv(test_path, index=False)\ny_train.to_csv(y_train_path, index=False, header=True)\ny_test.to_csv(y_test_path, index=False, header=True)\n\njoblib.dump(preprocessor, MODELS_DIR / 'preprocessor.pkl')\nprint('Exported cleaned dataset, processed splits, and fitted preprocessor.')"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "pd.DataFrame({\n    'dataset': ['X_train_processed', 'X_test_processed', 'y_train', 'y_test'],\n    'rows': [len(X_train_processed_df), len(X_test_processed_df), len(y_train), len(y_test)],\n    'columns': [X_train_processed_df.shape[1], X_test_processed_df.shape[1], 1, 1]\n})"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Preprocessing Notes\n- The KNN imputer preserves realistic neighbourhood structures when filling occasional numeric gaps.\n- Regional averages (`continent_life_expectancy_mean`) and country historical averages add macro- and micro-level context.\n- The exported files in `data/processed/` are ready for reuse in the modelling notebook and the Streamlit demo."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}