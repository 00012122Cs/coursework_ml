# Machine Learning & Data Analytics Coursework  
### University ID: 00012122  
### Module: 6COSC017C-n â€” Machine Learning and Data Analytics  
### Coursework Weight: 50%  

---

## ğŸ“Œ Project Overview
This project implements an end-to-end **machine learning pipeline** using a real-world dataset taken from the **World Health Organization (WHO) Global Health Observatory**. The aim is to analyze, preprocess, model, evaluate, and deploy a predictive system focused on **Life Expectancy** across different countries, years, and demographic groups.

The coursework includes:
- A full **Exploratory Data Analysis (EDA)**
- **Data preprocessing** (cleaning, missing values, scaling, encoding)
- Training **three or more ML models**
- **Model evaluation & comparison**
- A **Streamlit multi-page web application**
- Full **reproducibility** (requirements.txt + structured notebooks)
- Version-controlled development with meaningful commits

Dataset URL (Official WHO API):  
https://ghoapi.azureedge.net/api/WHOSIS_000001?$format=csv

---

## ğŸ“‚ Repository Structure

```
coursework_ml/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ life_expectancy.csv          # Raw WHO API export (JSON payload)
â”‚   â””â”€â”€ processed/                   # Automatically created for cleaned datasets
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                 # Exploratory data analysis
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb       # Data cleaning, feature engineering, exports
â”‚   â””â”€â”€ 03_model_training.ipynb      # Pipelines, tuning, evaluation, model saving
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ Home.py                      # Landing page
â”‚   â”œâ”€â”€ utils.py                     # Shared preprocessing/model utilities
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ 1_ğŸ“Š_EDA.py
â”‚       â”œâ”€â”€ 2_âš™ï¸_Preprocessing.py
â”‚       â”œâ”€â”€ 3_ğŸ¤–_Model_Training.py
â”‚       â””â”€â”€ 4_ğŸ“ˆ_Evaluation.py
â”œâ”€â”€ models/                          # Saved pipeline + metrics (generated after training)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

1. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```
2. **Open the notebooks**
   - Launch Jupyter Lab/Notebook and run the files in `notebooks/` sequentially:
     1. `01_eda.ipynb`
     2. `02_preprocessing.ipynb`
     3. `03_model_training.ipynb`
   - These notebooks reproduce the full coursework pipeline, export processed datasets to `data/processed/`, and save the best model to `models/final_model.pkl`.

3. **Run the Streamlit dashboard**
   ```bash
   streamlit run streamlit_app/Home.py
   ```
   - Navigate across the sidebar pages (EDA â†’ Preprocessing â†’ Model Training â†’ Evaluation).
   - The Streamlit app reuses the same preprocessing code, lets you re-train models interactively, and supports batch prediction via CSV upload.

---

## ğŸ§ª Deliverables

- **Data**: `data/life_expectancy.csv` contains the WHO indicator `WHOSIS_000001`.
- **Notebooks**: Document EDA, preprocessing with feature engineering, and model development with MAE/RMSE/RÂ² comparisons plus GridSearchCV tuning.
- **Models**: Best-performing pipeline persisted as `models/final_model.pkl` together with `models/model_performance.csv`.
- **App**: Multi-page Streamlit experience for analysis, preprocessing inspection, training, and evaluation/deployment.

Follow the notebooks and app to regenerate every artefact and align with WIUT coursework requirements.
